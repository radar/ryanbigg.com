<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-12-06T10:01:28+11:00</updated><id>http://localhost:4000/feed.xml</id><entry><title type="html">Using Elastic Search’s Profile API</title><link href="http://localhost:4000/2024/12/using-elastic-searchs-profile-api" rel="alternate" type="text/html" title="Using Elastic Search’s Profile API" /><published>2024-12-06T00:00:00+11:00</published><updated>2024-12-06T00:00:00+11:00</updated><id>http://localhost:4000/2024/12/using-elastic-searchs-profile-api</id><content type="html" xml:base="http://localhost:4000/2024/12/using-elastic-searchs-profile-api"><![CDATA[<p>Recently, we saw that one of our production applications was experiencing very long query times when users were searching for their customers, with some queries taking as long as 60 seconds.</p>

<p>We use Elastic Search to power this search (even though Postgres’ own full-text search would’ve been suitable!) and the query we wrote for Elastic Search was this one written about 10 years ago:</p>

<pre><code class="language-json">{
  "query": {
    "bool": {
      "must": [
        {
          "query_string": {
            "query": "Ryan*"
          }
        }
      ],
      "filter": [
        {
          "bool": {
            "must": [
              {
                "terms": {
                  "merchant_id": [2]
                }
              }
            ]
          }
        }
      ]
    }
  }
}
</code></pre>

<p>This query will search for the query string “Ryan*” across all fields on all documents within the <code>customers</code> index. Given the application has grown substantially over the last 10 years, there’s now <em>a lot</em> of customer documents to search through. As the number of documents grow, the amount of time to search through those documents gets increasingly slower.</p>

<p>In order to figure out <em>why</em> this query was slow rather than “big data” and vibes-driven-development, I turned to the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html">Profile API within Elastic Search</a>. We can use this by adding <code>profile: true</code> to the top of any query string:</p>

<pre><code class="language-json">{
  "profile": true,
  "query": {
    "bool": {
  ...
</code></pre>

<p>This profile key gives us a <em>very</em> detailed breakdown of what a query is doing, including how long each of its distinct parts are taking. Fortunately for us, this query is relatively “simple” and only consists of one very large operation: search across all document fields for a wildcarded query string.</p>

<p>The first thing I noticed when looking at this output is that the number of fields are quite long:</p>

<pre><code>{
  "profile": {
    "shards": [
      {
        "id": "[JzYnfX2ORHiGumsVoL3jhg][customers][2]",
        "searches": [
          {
            "query": [
              {
                "type": "BooleanQuery",
                "description": "(last_name.keyword:Ryan* | &lt;a lot of fields&gt;"
              }
            ]
          }
        ]
      }
    ]
  }
}
</code></pre>

<p>The excessive amount of fields are a combination of regular customer information and address information. So my first thought was could we limit the amount of fields that we’re letting users search through. To do this, we can use <code>fields</code> on the query to say “only search these fields”:</p>

<pre><code class="language-json">{
  "profile": true,
  "query": {
    "bool": {
      "must": [
        {
          "query_string": {
            "query": "Ryan*",
            "fields": [
              "first_name",
              "last_name",
              "email",
              "reference",
              "card_token",
              "card_number",
              "public_id"
            ]
          }
        }
      ],
      "filter": [
        {
          "bool": {
            "must": [
              {
                "terms": {
                  "merchant_id": [2]
                }
              }
            ]
          }
        }
      ]
    }
  }
}
</code></pre>

<p>This time the profile output only contained the fields that I was interested in. These fields are all the fields we display in the UI for customers – notably <code>card_number</code> is a masked version of the number.</p>

<p>After making this change, the query time went from multiple-digit seconds to single-digit seconds. This is because the query now looks in fewer locations across each document within its index. Importantly, the query also passed all our feature tests around searching within our application too.</p>

<p>I still felt like there was space to improve the query. Did we really need it to use a wildcard search, given that Elastic Search is pretty decent at matching text? So I tried it again without the wildcard on the end of the query:</p>

<pre><code class="language-json">{
  "profile": true,
  "query": {
    "bool": {
      "must": [
        {
          "query_string": {
            "query": "Ryan",
            "fields": [
              "first_name",
              "last_name",
              "email",
              "reference",
              "card_token",
              "card_number",
              "public_id"
            ]
          }
        }
      ],
      "filter": [
        {
          "bool": {
            "must": [
              {
                "terms": {
                  "merchant_id": [2]
                }
              }
            ]
          }
        }
      ]
    }
  }
}
</code></pre>

<p>This query now operated in two-digit milliseconds. Without using a wildcard, the query is pre-analysed by Elastic Search and breaks it down into tokens that can then be matched to pre-analysed documents within the index.</p>

<p>Comparing the two profile outputs, the one with the wildcard shows a series of <code>MultiTermQueryConstantScoreWrapper</code>, matching against all different fields. The one without the wildcard shows a range of different ones such as <code>TermQuery</code> for fields classified as <code>term</code>, which will match faster as we’re searching based on the pre-analysed data within the index.</p>

<p>(And if we want to be completely un-scientific about it, the profile output for wildcard searching is 1,100 lines, while the profile output for non-wildcard searching is only 700 lines. Fewer lines of profiling output is a very good indicator that the searcher is doing less work!)</p>

<p>This is more suitable for matching against customer records in most circumstances, as our users are searching either by a customer’s full name or their email addresses. In rarer cases, they’re using reference values, and when that happens it appears to be the full reference value. The <code>card_token</code> and <code>card_number</code> fields are used the least frequently.</p>

<p>I’m going to be rolling out this change next week and I have strong faith in its ability to reduce search time for people. I now have an additional tool in my toolbelt for diagnosing slow Elastic Search queries, and a better understanding from the profile output as to what different queries are doing.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Recently, we saw that one of our production applications was experiencing very long query times when users were searching for their customers, with some queries taking as long as 60 seconds.]]></summary></entry><entry><title type="html">React is fine</title><link href="http://localhost:4000/2024/11/react-is-fine" rel="alternate" type="text/html" title="React is fine" /><published>2024-11-26T00:00:00+11:00</published><updated>2024-11-26T00:00:00+11:00</updated><id>http://localhost:4000/2024/11/react-is-fine</id><content type="html" xml:base="http://localhost:4000/2024/11/react-is-fine"><![CDATA[<p><a href="https://joshcollinsworth.com/blog/antiquated-react">This post called “Things you forgot (or never knew) because of React</a> by Josh Collinsworth is a good read about the deficiencies of React, and includes a good comparison between React and the other frontend frameworks at the moment.</p>

<p>And yet, I find myself and my team consistently being productive with React. The main application we develop uses a lot of it, a second application has had a re-write of a key component into React, and other apps have “React sprinkles” through them. It’s a versatile framework!</p>

<p>In our main application, we have React componentry brought in from our design system, which is then bundled together into much larger components. Most of these are static components: take some data, render an element a certain way depending on that data. Where we use React’s “reactivity” is typically in a few small places:</p>

<ol>
  <li>Make this menu appear when its “open” button is clicked</li>
  <li>Show a loading spinner while a request is processing</li>
  <li>Display a validation error message if a field doesn’t pass validation (for example: a card expiry that is in the past, or an invalid card number – neither of which browsers support natively.)</li>
</ol>

<p>We also leverage a lot of what GraphQL provides by exporting types from the backend to then inform types on the frontend. Yes, we <em>could</em> do this <a href="https://the-guild.dev/graphql/codegen/docs/guides/svelte">with another framework</a> but even adding a single component that uses this framework doubles our team’s cognitive load for what seems like minimal benefit. These GraphQL types then go on to inform what the data used in those React components of the app should look like.</p>

<p>In terms of styling: we use Tailwind, which I covered in <a href="https://ryanbigg.com/2024/03/tailwind-has-won">“Tailwind has won”</a>. We don’t need styles that are limited in scope to a particular component because of how Tailwind operates – it’s all utility classes and they don’t apply <em>until you apply them</em>. Yes, you can have really really long class lists, but you can compress these down into your own utility classes, as we’ve done with things such as <code>.zeal-button-primary</code>.</p>

<p>Two things that we don’t have yet in how our applications operate are server-side rendering and web components.</p>

<p>Server-side-rendering would mean that we could get away with displaying dynamic data, still using our existing React components, without displaying loading spinners all over the place. It’s a trivial thing, but a loading spinner makes me think “this app could’ve taken an extra 100ms to fetch this data in the original request”. We could probably get there with a little effort, though I do wonder how it’d work with the GraphQL things we have in place.</p>

<p>On web components: I would like to move parts of our design system towards adopting those. I’m somewhat wary of the “newness” of interactivity between React + web components, and also about the “split brain” of switching between “this is a React component” and “this is a web component”. But I think web components is ultimately where we’re headed, as the browser always wins.</p>

<p>(And on one more note: Don’t get me started on Stimulus.)</p>]]></content><author><name></name></author><summary type="html"><![CDATA[This post called “Things you forgot (or never knew) because of React by Josh Collinsworth is a good read about the deficiencies of React, and includes a good comparison between React and the other frontend frameworks at the moment.]]></summary></entry><entry><title type="html">Ruby Retreat 2024</title><link href="http://localhost:4000/2024/10/ruby-retreat-2024" rel="alternate" type="text/html" title="Ruby Retreat 2024" /><published>2024-10-22T00:00:00+11:00</published><updated>2024-10-22T00:00:00+11:00</updated><id>http://localhost:4000/2024/10/ruby-retreat-2024</id><content type="html" xml:base="http://localhost:4000/2024/10/ruby-retreat-2024"><![CDATA[<p>This weekend was Ruby Retreat (a re-branded <a href="https://rails.camp/">Rails Camp</a>) where we gathered 60 people from Australia and New Zealand at a camp ground in Warrnambool, the town where I live. Ruby Retreat is an un-conference event where Rubyists of all skill levels come together to hang out from a Friday night until a Monday morning. There may have even been some non-Rubyists there too. We provided catering and beds, they provided the activities.</p>

<p>The idea for this event came out of a Ruby Australia conference earlier in the year when a group of Ruby friends pulled me aside and said “we should have a camp again!”. We’ve had about 27 of these in the past, with them dating back to 2007. Covid threw a spanner in the works and we ended up not running one for a while.</p>

<p>After a few suggestions of locations, I suggested Warrnambool, pitching that there’s a venue there that’s close to the beach and there’s plenty of activities near by. It sounded enough like a good idea that I was suddenly made de facto organiser of the camp. Others such as Jupiter Haehn, Kieran Andrews, Ed Tippett and Richie Khoo helped out too and offered very good advice.</p>

<h2 id="selling-tickets">Selling tickets</h2>

<p>We sold tickets to the camp by advertising them at https://retreat.ruby.org.au by recycling a previous version of the website, and selling them through <a href="https://ti.to">Tito</a>. We eye-balled a rough estimate on what the camp would cost us and used that to set the ticket prices ($350 full price, $300 concession). We weren’t too far off, with the debt (measured in &lt; $2,000 terms) being covered by Ruby Australia’s sponsors for the year.</p>

<p>I think we could’ve done a better job with marketing the camp, probably by having organisers (or proxies) visit each meetup around the country and spruik the benefit of it.</p>

<p>We ended up selling 60 tickets to the event and also gave an option for people to put in for an Opportunity Ticket cost. This was enough to bring one extra person <em>for free</em> along to the camp. We didn’t make a big deal about it at the camp but I reckon it is a big deal! Generosity like this is awesome to see from this community.</p>

<h2 id="location-location-location">Location, Location, Location</h2>

<p>The camp site was Warra Gnan Coastal Camp, located 600m from the ocean. Liasing with the camp site owners was a relatively straightforward affair with tours given early on in the planning process. Big “ticks” for why we picked that place (besides it being 3km from my house) was the location, the kitchen area and the sufficient beds down the back area. Some of the rooms contained en suites with toilets and showers, while the others had a pair of shower rooms, one for men and one for women.</p>

<p>Other perks included the grassed area at the back for tent setup (some people like to camp away from the snorers!), and ample outside room for people who wanted to catch some sun during the day.</p>

<p>Closer towards the camp the camp site also installed a projector in the main space as well as two heaters. We made ample use of this projector for talks at beginning and end of camp. We didn’t end up needing the heaters but in the colder months they’d be a necessity.</p>

<p>The location also meant people could get to Thunder Point, Stingray Bay, the main beach, Lake Pertobe and the Sunday markets by walking. Having it so close to town as well meant supplies could be easily gathered if people needed anything that the camp didn’t have. Warrnambool’s a big enough town that there’s multiple Coles, Woolworths and Aldis.</p>

<h2 id="catering">Catering</h2>

<p>Catering was provided by the Beach Kiosk Cafe. After being inflicted with Tinned Spaghetti Bolognese In A Big Pot and Some Toast with Spreads masquerading as dinner and/or lunch at a long-ago past event, I wanted something better for catering options this time around. I reached out to the Beach Kiosk who I know through a family-connection and they were happy to provide the catering. We catered for lunch and dinners with this menu:</p>

<blockquote>
  <p>DF = Dairy Free, GF = Gluten Free, V = Vegetarian, VG = Vegan</p>

  <p><strong>Dinner 18th October</strong></p>

  <p>Slow braised lamb shoulder in with tomato paprika sauce(DF GF)</p>

  <p>Grilled chicken with onions, capsicum, and olives(DF GF)</p>

  <p>Roasted half eggplant w tomato and paprika(VG)</p>

  <p>Ratatouille(VG GF DF)</p>

  <p>Green beans, feta and pine nuts(GF V)</p>

  <p>Garlic mash potato(GF)</p>

  <p>Banana fritter with vanilla ice cream
Sticky rice w cinnamon coconut sauce with banana and berries(VG DF GF)</p>

  <p><strong>Lunch Oct 19</strong></p>

  <p>Stir fry egg noodles with chickened veggies(DF VGA)</p>

  <p>Pork belly fried rice(GF DF VGA)</p>

  <p>Fruit Salad</p>

  <p><strong>Dinner Oct 19</strong></p>

  <p>Ginger soy braised beef with shitake mushroom (DF GF)</p>

  <p>Crispy tofu with miso chilli with cauliflower, mushroom and herbs (VG GF DF)</p>

  <p>Asian Greens w soy and garlic(VG)</p>

  <p>Fragrant rice(VG DF GF)</p>

  <p>Strawberry panacotta with coconut chocolate mousse and fresh berries (VG DF GF)</p>

  <p><strong>Lunch Oct 20</strong></p>

  <p>Roast pumpkin, roast cauliflower, mushroom, beetroot hummus, haloumi, seeds, and cashew aioli (VG GF DF)</p>

  <p>Fruit Salad</p>

  <p><strong>Dinner Oct 20</strong></p>

  <p>Roast cauliflower and fennel paella (VG GF DF)</p>

  <p>Chicken chorizo paella(GF DF)</p>

  <p>Salad with mix lettuce, carrots, red onion, cucumber and fennel, with vinaigrette dressing(VG DF GF)</p>

  <p>Raspberry Cheesecake(GF)</p>

</blockquote>

<p>You’ll notice that most meals were suitable for vegans or vegetarians. This is so that we could include as many people as possible for lunches and dinners. This food worked out to $60/head/day. It was exceptional each night and as someone who has been called “food-oriented” on more than one occasion, I really appreciated the quality and good mix of healthy veg and meat. And desserts! Other camp attendees rated the food highly too!</p>

<p>On top of this, we also bought breakfast cereals, milk, coffee, bread and spreads so people could build their own breakfasts. Jupiter also bought an absolute wealth of snacks from Costco for cheap. Kieran cooked trays of scrambled eggs on the morning. On the Sunday and Monday mornings we also made a tray of pancakes for early risers. Next time I’d bring a second pan so I could cook them faster!</p>

<p>All 3 mornings had the coffee van turn up for 2 hours (8-10 Saturday/Sunday, 7-9 Monday) where people could order their coffees and we covered the cost of those too.</p>

<p>I was arranging the washing up on Friday night and outta nowhere an attendee, Michael Morris, self-organised a schedule for the rest of the camp, taping a laminated piece of paper to a wall with a whiteboard-marker schedule on it. I damn near cried it was that nice of an offer. The cleaning up on Saturday/Sunday/Monday was a lot easier than Friday to the point where I didn’t need to think about it for the rest of the camp.</p>

<p>In terms of drinks, we catered by buying some juices and milk, and others brought their own soft drinks or alcohol and put them into the shared fridge. Rails Camps in the past have catered for their own alcohol but we decided not to this time. We spent the alcohol money on kick-ass food instead. Those that wanted to drink could still do it, just on their own dollar. Nobody complained.</p>

<h2 id="transport">Transport</h2>

<p>We had a few people fly in from New Zealand and one guy flew in from Japan (!), but most people came in from around Australia and ended up arriving in Melbourne. Warrnambool has a <em>private</em> airport, so there’s no direct commercial flights in.</p>

<p>Some of those people drove over from Melbourne (despite the stormy conditions on Friday afternoon). The remaining group of around 20 caught the train over, with the camp funding the $20/ticket/day cost for those tickets. We had Brent Chuang from Fat Zebra being the “ticket holder” for the train tickets as he was catching the train from Melbourne. I didn’t mind this too much, but I would’ve preferred V/Line offered an electronic option that was easier to manage than paper tickets.</p>

<p>As the camp approached it became clearer and clearer that the weather on Friday was going to be very bad, so we ended up booking a bus at $10/head for that day. And glad we did, as the weather was stormy all day. Attendees who caught the bus ended up being treated to a (surprise) mini-tour of Warrnambool too thanks to the bus tour company. They arrived dry at the camp, which is always a nice way to get a start to an event.</p>

<p>There was no bus back on the Monday afternoon as the time of venue departure was 9am and the train was due to depart at 12pm, and the weather was <em>exceptionally sunny</em>. This left people able to explore Warrnambool more and find their own way to the station.</p>

<h2 id="inside-the-building-itself">Inside the building itself</h2>

<p>Internet: This time there was no internet access at the camp <em>by choice</em> rather than from past camps where it’s absolutely an <em>impracticality</em> due to location (i.e. the last Ruby Retreat, held up the top of a mountain in New Zealand). I ummed and ahhed about setting up a proper router with a 5G sim in it from Telstra but ultimately decided people could sort out their own access with their hotspots on their phones. It seemed to work alright. I think with a shared router between 50 people you’d run into people/machines being greedy, or random network issues like “this router has handed out 32 DHCP addresses and refuses to do anymore”. Perhaps we dodged a bullet.</p>

<p>Tables &amp; powerboards: Some of the attendees setup the tables and powerboards with minimal direction (thank you!!). We found that we were mildly <em>short</em> of powerboards for the number of people, but ultimately other people ended up bringing their own and making up the numbers. There was just enough power sockets in the walls for these and we ran out extension cables from these sockets to power the boards.</p>

<p>We were at capacity for the tables at the camp as well (but strangely, not the provided chairs…), and perhaps if we were to use this venue again we’d have to hire some more tables. Fortunately, I found an events hire company that would do that for a reasonable rate of $18/table. We didn’t end up needing them this time, but I imagine with higher attendance it’d be high on the list of stuff to organise. There’s room in the venue for more. Not only was this where people sat and worked, but it’s also where they had dinner. We also had tables outside that people made use of for this too.</p>

<p>I couldn’t imagine having an attendance above about 75 adults at the camp because it’d be super cozy in the main hall.</p>

<h2 id="activities">Activities</h2>

<p>As it’s an unconference we’re extremely loosey-goosey when it comes to actually scheduling anything in. We had the welcome on the Friday night, a Ruby Australia AGM on Saturday afternoon, and a demo night on Sunday night. That’s it. If anyone else wanted to do anything else, they had to make up their own plans. A lot of people spent the weekend hacking on things, and a similar number spent the time just hanging out. You make the event how you want to make it.</p>

<p>I ended up playing Magic for a few hours on Saturday against Kieran and whoever else wanted to join us. I also extended my <a href="https://github.com/radar/mtg">Magic project</a> with a few new cards.</p>

<p>Jupiter ran a few sessions on Blood on the Clocktower, which is more than a spiritual successor to the traditional Werewolf. That was really fun to play! I love the diversity of the roles (instead of a few sporadic “specials”), the interplay between alive &amp; dead people, and the mechanics of the imp + minion. Definitely recommend!</p>

<p>A group formed around a table-top game like DND but not DND (I didn’t catch the name!) on Sunday afternoon and played that long enough for the guy who was running it to turn a great shade of red from his sunburn.</p>

<p>Other attendees ended up touring around Warrnambool doing things like riding the flying fox at Lake Pertobe, walking around the coastal walk at Thunder Point or visiting the nearby beaches. Some people were even able to make bookings at the Deep Blue Hot Springs. Others spent time further afield going out to Tower Hill and other locations.</p>

<h2 id="would-i-do-it-again">Would I do it again?</h2>

<p>Yes. This was really fun to organise and be a part of. I don’t think I’d run one again in the next 6 months, but perhaps in a year? We’ll see.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[This weekend was Ruby Retreat (a re-branded Rails Camp) where we gathered 60 people from Australia and New Zealand at a camp ground in Warrnambool, the town where I live. Ruby Retreat is an un-conference event where Rubyists of all skill levels come together to hang out from a Friday night until a Monday morning. There may have even been some non-Rubyists there too. We provided catering and beds, they provided the activities.]]></summary></entry><entry><title type="html">Use classes to represent data</title><link href="http://localhost:4000/2024/09/use-classes-to-represent-data" rel="alternate" type="text/html" title="Use classes to represent data" /><published>2024-09-18T00:00:00+10:00</published><updated>2024-09-18T00:00:00+10:00</updated><id>http://localhost:4000/2024/09/use-classes-to-represent-data</id><content type="html" xml:base="http://localhost:4000/2024/09/use-classes-to-represent-data"><![CDATA[<p><strong>Accessing JSON structures through strings is an anti-pattern and a sign of lazy programming.</strong></p>

<p>When we write Ruby code, we use classes to represent data within our own applications. Typically, these are models from within the Rails application. But I’ve seen a repeated pattern of Rubyists consuming JSON data <em>without first casting that to an object</em>.</p>

<p>It opens the door for mistakes to be made, especially when it comes to typos in strings. It’s too easy to get muddled up and think things are different to what they are — for example, a string that’s under_scored is different to one that’s camelCased. Accessing values in a JSON payload with the wrong key will result in a <code>nil</code> value.</p>

<p>Take for example this JSON object:</p>

<pre><code class="language-json">{
  "contacts": [
    {
      "first_name": "Ryan",
      "last_name": "Bigg",
      "address": {
        "address_line_1": "1 Test Lane"
      }
    }
  ]
}
</code></pre>

<p>To access this data, we might mistakenly write this code in Ruby:</p>

<pre><code class="language-ruby">data[0]["address"]["adddress_line_1"]
</code></pre>

<p>Not only is this full to the brim of unnecessary punctuation, but this will then return a nil value as there is no such key as <code>adddress_line_1</code> – we’ve mistakenly added a 3rd “d”.</p>

<p>To get around this, we could define a struct class to represent these contacts</p>

<pre><code class="language-ruby">Contact = Struct.new(:first_name, :last_name, :address, keyword_init: true)
</code></pre>

<p>We could even go a step further and add a helper method for combining the first and last name:</p>

<pre><code class="language-ruby">Contact = Struct.new(:first_name, :last_name, :address, keyword_init: true) do
  def full_name
    "#{first_name} #{last_name}"
  end
end
</code></pre>

<p>However, this only addresses the outer-layer of contacts, and not the inner-layer of addresses. To get that information, we would still need to use the bracket syntax:</p>

<pre><code class="language-ruby">puts contacts.first["address"]["address_line_1"]
</code></pre>

<p>Or, we can use <code>dig</code>, which is a little neater but still has lots of punctuation:</p>

<pre><code class="language-ruby">puts contacts.dig(0, "address", "address_line_1")
</code></pre>

<p>To tidy this up further, we can use <code>dry-struct</code> instead of Ruby’s built-in structs, and then define two classes to represent both contacts and addresses.</p>

<pre><code class="language-ruby">module Types
  include Dry.Types()
end

class Address &lt; Dry::Struct
  transform_keys(&amp;:to_sym)

  attribute :address_line_1, Types::String
end

class Contact &lt; Dry::Struct
  transform_keys(&amp;:to_sym)

  attribute :first_name, Types::String
  attribute :last_name, Types::String
  attribute :address, Address

  def full_name
    "#{first_name} #{last_name}"
  end
end
</code></pre>

<p>We can then use this to load the data by running:</p>

<pre><code class="language-ruby">contacts = data["contacts"].map &amp;Contact.method(:new)
</code></pre>

<p>(Keen observers will note that we could have an outer structure with a <code>contacts</code> attribute too!)</p>

<p>When we load the contact + address data like this, we can then access the data within it like a typical Ruby model:</p>

<pre><code>contacts.first.address.address_line_1
</code></pre>

<p>Only the most minimal amount of punctuation required. Then, if we happen to mis-type the key again:</p>

<pre><code>contacts.first.address.adddress_line_1
</code></pre>

<p>We get a runtime error:</p>

<pre><code>undefined method `adddress_line_1' for #&lt;Address address_line_1="1 Test Lane"&gt; (NoMethodError)

contacts.first.address.adddress_line_1
                      ^^^^^^^^^^^^^^^^
</code></pre>

<p>By using <code>dry-struct</code> we’ve added some guardrails around our data structure, and avoided the possibility for mis-typing keys. On top of this, we can enforce that certain keys are always required by using the <code>required</code> method on the type.</p>

<pre><code class="language-ruby">class Contact &lt; Dry::Struct
  transform_keys(&amp;:to_sym)

  attribute :first_name, Types::String.required
  attribute :last_name, Types::String.required
  attribute :address, Address

  def full_name
    "#{first_name} #{last_name}"
  end
end
</code></pre>

<p>While we’ve define just string types for our values, we may have additional fields (such as a contact’s date of birth) that we could enforce stricter types on if we wished as well:</p>

<pre><code class="language-ruby">class Contact &lt; Dry::Struct
  transform_keys(&amp;:to_sym)

  attribute :first_name, Types::String.required
  attribute :last_name, Types::String.required
  attribute :date_of_birth, Types::Date.required
  attribute :address, Address

  def full_name
    "#{first_name} #{last_name}"
  end
end
</code></pre>

<p>All this ensures that JSON data that we ingest is modeled in a similar manner to the models within our application. We avoid the time sinks of mis-typed data resulting in nils. We avoid the excessive punctuation of accessing nested data. And ultimately: We have type enforcement for the data that we’re ingesting.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Accessing JSON structures through strings is an anti-pattern and a sign of lazy programming.]]></summary></entry><entry><title type="html">Debugging Checklist</title><link href="http://localhost:4000/2024/07/debugging-checklist" rel="alternate" type="text/html" title="Debugging Checklist" /><published>2024-07-09T00:00:00+10:00</published><updated>2024-07-09T00:00:00+10:00</updated><id>http://localhost:4000/2024/07/debugging-checklist</id><content type="html" xml:base="http://localhost:4000/2024/07/debugging-checklist"><![CDATA[<p>Above my screen, I have simple reminder: “IT IS ALWAYS TIMEZONES.” It used to be a simple black-and-white sign until my daughter decided it needed to be turned into a brilliant rainbow of a warning.</p>

<p>The sign was put up after experiencing not one <em>but two</em> timezone-related bugs within a relatively close proximity. Periodically, I’ll see something similar crop up like a test failing before 10am, but not after, thanks to the differences between what day of the week it is in UTC vs my local computer (in +1000 or +1100, depending on the day).</p>

<p>In a work discussion yesterday we talked about debugging checklists and I wrote up one with what I could think of. I’m sharing it here as it might be useful to others. Maybe there’ll be more signs that come out of it.</p>

<p><strong>First: have you eaten or drunk anything recently? Do you need to take a break?</strong></p>

<p><strong>Then:</strong></p>

<ol>
  <li>Are you in the right app?</li>
  <li>Right file?</li>
  <li>Right function?</li>
  <li>Is the function spelled correctly?</li>
  <li>If you’re running locally:
    <ol>
      <li>Is the server up?</li>
      <li>Is the server running on the port you expect?</li>
    </ol>
  </li>
  <li>Is there information in the logs?
    <ol>
      <li>Can you add more logs to provide more useful information? (Usually, yes.)</li>
      <li>Can you reduce other logging to focus on just what you need?</li>
    </ol>
  </li>
  <li>Are you sure you’re in the right environment (local / staging, etc) for this?</li>
  <li>Can you inspect this function to determine if it is what you expect?
    <ol>
      <li>Is the input what you expect?</li>
      <li>Is the output what you expect?</li>
      <li>Are there intermediary steps where the input is transformed into a new form?</li>
    </ol>
  </li>
  <li>Is it a string issue?
    <ol>
      <li>Does casing matter in this situation?</li>
      <li>Are you comparing this string to another? Inspect both to see any differences.</li>
      <li>Does pluralization or non-pluralization of the string matter?</li>
      <li>Are there extra characters blank spaces?</li>
      <li>Null-byte prefix? (check with #codepoints)</li>
    </ol>
  </li>
  <li>If the behaviour is new:
    <ol>
      <li>Do you see this behaviour on the main branch, or just your own?</li>
      <li>If you see it on the main branch, can you use <code>git bisect</code> to find out when this issue was introduced?</li>
      <li>Were there packages updated recently that may have introduced this bug?</li>
    </ol>
  </li>
  <li>Is an exception happening, and then being rescued too quickly by something like <code>rescue</code> or <code>rescue StandardError</code>?
    <ol>
      <li>Can you narrow down the exception class to something more specific?</li>
    </ol>
  </li>
  <li>If it is a time bug:
    <ol>
      <li>Is it a different day in UTC compared to your local time?</li>
      <li>Do you need to freeze time for this test?</li>
      <li>Are you certain the time zone your code is running in is the right time zone?</li>
    </ol>
  </li>
  <li>If it’s an integer / float bug:
    <ol>
      <li>Are there numbers being rounded?</li>
      <li>Can you push the rounding “down” the stack, so it is one of the final operations to simplify?</li>
    </ol>
  </li>
  <li>If it’s a browser issue:
    <ol>
      <li>Can you reproduce this issue in a different browser?</li>
      <li>Are you trying to use a browser API that is not currently supported in this browser?</li>
      <li>Are there any errors displayed in the console?</li>
      <li>Were there any network requests that failed, or contain errors?</li>
    </ol>
  </li>
  <li>If this code depends on environment variables:
    <ol>
      <li>Is the environment variable spelled correctly?</li>
      <li>Is the value of that variable what you expect?</li>
    </ol>
  </li>
  <li>If this code depends on a configuration file:
    <ol>
      <li>Is the configuration file in the right place?</li>
      <li>Is the configuration key set up where you expect it?</li>
      <li>Does that key have the right value?</li>
    </ol>
  </li>
</ol>]]></content><author><name></name></author><summary type="html"><![CDATA[Above my screen, I have simple reminder: “IT IS ALWAYS TIMEZONES.” It used to be a simple black-and-white sign until my daughter decided it needed to be turned into a brilliant rainbow of a warning.]]></summary></entry><entry><title type="html">Separation of data and view layers in React components</title><link href="http://localhost:4000/2024/07/separation-of-react-components-with-graphql" rel="alternate" type="text/html" title="Separation of data and view layers in React components" /><published>2024-07-05T00:00:00+10:00</published><updated>2024-07-05T00:00:00+10:00</updated><id>http://localhost:4000/2024/07/separation-of-react-components-with-graphql</id><content type="html" xml:base="http://localhost:4000/2024/07/separation-of-react-components-with-graphql"><![CDATA[<p>In my <a href="https://leanpub.com/apollo-handbook">Apollo Handbook</a> I cover how to use React + Apollo to interact with a GraphQL API. I thought I’d share a pattern from that book that is making working with this library easier, in particular the pattern where we separate the <em>data layer</em> from the <em>view layer</em> of a component.</p>

<p>With Apollo and <a href="https://the-guild.dev/graphql/codegen">GraphQL code generator</a>, we get React hooks that we can use in our component. It can be tempting to combine both these layers together in a single component:</p>

<pre><code class="language-tsx">const Product = (id: string) =&gt; {
  const { data, loading, error } = usePurchaseQuery({ variables: { id } });

  // handle loading + error states...

  const { product } = data;

  return (
    &lt;div&gt;
      &lt;h1&gt;{product.name}&lt;/h1&gt;

      {product.description}
    &lt;/div&gt;
  );
};
</code></pre>

<p>But then this component is tied too closely to where it gets its data from, and if you want to test (such as in React Testing Library) how your components behave when they receive certain props, you must then stub the data layer.</p>

<p>An alternative approach that I like is separating the data and view layers into two distinct functions. The first function is the data function:</p>

<pre><code class="language-tsx">const WrappedProduct = (id: string) =&gt; {
  const { data, loading, error } = usePurchaseQuery({ variables: { id } });

  // handle loading + error states...

  const { product } = data;

  return (
    &lt;Product {...product} /&gt;
  );
}
</code></pre>

<p>Its responsibility is to grab the data and pass it to the view component. The <code>loading</code> and <code>error</code> states can also be handled by this component, or something such as a higher-order <code>ErrorBoundary</code> component.</p>

<p>When the <code>Product</code> component receives the props, we can use the type from the query itself to inform the view component of the correct types:</p>

<pre><code class="language-tsx">
import ProductQuery from "@graphql/types"

type ProductType = ProductQuery["product"]
const Product = ({ name, description }: ProductType) =&gt; {
   return (
    &lt;div&gt;
      &lt;h1&gt;{product.name}&lt;/h1&gt;

      {product.description}
    &lt;/div&gt;
  );
}
</code></pre>

<p>This is a small contrived example, but for a more complicated component this would make it easier to use this component in React Testing Library to run assertions on its behaviour, or to render it in Storybook to see how it looks.</p>

<p>Rather than stubbing the GraphQL request / response cycle, we can instead pass typed props along to the component.</p>

<p>Here’s what our test file might look like:</p>

<pre><code class="language-tsx">type ProductType = ProductQuery["product"]

const product: ProductType = {
  name: "Rolo Tomassi - Where Myth Becomes Memory",
  description: "2022 Album"
}

it("displays a product name", () =&gt; {
  render(&lt;Product {...product}&gt;)

  expect(screen).toHaveContent("Rolo Tomassi - Where Myth Becomes Memory")
})
</code></pre>

<p>If we’re concerned with how the GraphQL layer is handling its response, then we still have the option to test that layer with something like <a href="https://mswjs.io/docs/api/graphql/">Mock Service Worker’s GraphQL API</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[In my Apollo Handbook I cover how to use React + Apollo to interact with a GraphQL API. I thought I’d share a pattern from that book that is making working with this library easier, in particular the pattern where we separate the data layer from the view layer of a component.]]></summary></entry><entry><title type="html">Decreasing Ruby app build times</title><link href="http://localhost:4000/2024/06/make-rspec-tests-go-faster" rel="alternate" type="text/html" title="Decreasing Ruby app build times" /><published>2024-06-28T00:00:00+10:00</published><updated>2024-06-28T00:00:00+10:00</updated><id>http://localhost:4000/2024/06/make-rspec-tests-go-faster</id><content type="html" xml:base="http://localhost:4000/2024/06/make-rspec-tests-go-faster"><![CDATA[<p><strong>EDIT:</strong> I wrote these as notes for myself a few weeks ago when my brain wouldn’t stop spinning on this problem. Writing things down gets it out of my brain and lets me do simple things, like “engage in conversations” or “sleep”.</p>

<p>We’ve now undertaken <em>some</em> of this work mentioned in the post, and our builds have gone from 45 minutes down to as low as 14 minutes. The major thing that improved build time was making the build machines faster… but don’t discount the rest of the stuff in this post too. After all, tests are code, and all code should be maintained and made to perform when necessary.</p>

<hr />

<p>This week and next it’s the “cooldown sprint” at work where we prioritise addressing tech debt over regular feature development. As a part of that work, I’m working on bringing down the test run time on one of our biggest and well-tested Rails apps from its current mean duration of 45 minutes.</p>

<p>This 45 minute cost is paid thrice:</p>

<ol>
  <li>Once for your branch</li>
  <li>Once it gets to <code>develop</code> (shipped to staging environments)</li>
  <li>Once it gets to <code>master</code> (shipped to sandbox + production environments)</li>
</ol>

<p>So to get out a change of even just a single line to production takes 2.25 hours total, assuming you’re getting a median build time. 2.25 hours seems like an exorbitantly long time. And it is. Over the 8 hour work day, we would be able to ship 3.5 different changes to production.</p>

<p>This app has quite a number of end-to-end feature requests which follow this pattern:</p>

<ol>
  <li>Create a user + merchant account</li>
  <li>Create some relevant data</li>
  <li>Login as that user + merchant combo</li>
  <li>Navigate to page where the data is</li>
  <li>Make some assertions about what the page looks like or how it performs</li>
</ol>

<p>And a lot of these tests test business-critical features of our application, like that we can submit payments through our Virtual Terminal or that a payment plan is setup to reoccur on the correct schedule.</p>

<p>For these tests, we’ve relied a lot on Capybara running Selenium and a headless Chrome instance. This setup works exceptionally well for us, allowing us to write more Ruby code to test the Ruby code we’ve written in the app.</p>

<h2 id="straightforward-ways-of-solving-things">Straightforward ways of solving things</h2>

<p>There are some straightforward ways we could solve this slowness. We could upgrade the machines that run our tests. The current configuration is by no means at the top (or bottom) end for the configuration bracket for the type of machines. Faster machines surely mean faster tests, right? The caveat there is that faster machines also mean more dollars. Are there things we can do that don’t cost us money?</p>

<p>The other straightforward thing is to parallelise these tests out so that they don’t run in sequence all on the same machine. We did that, parallelising to 4 nodes and then to 8, using the wonderful <a href="https://knapsackpro.com">Knapsack Pro</a> gem. Knapsack suggests parallelising up to 19 nodes, but again this means more machines and more dollars. This could potentially block other builds on other projects from running as well, as we have a low ceiling on how many concurrent build machines we are running across the whole org. The moment we run two distinct builds for this project that would mean up to 38 build machines tied up.</p>

<p>If the tests for one build across 19 machines were to run for 5 minutes, the total cost would be $0.28USD. The old adage of developer time being expensive and computer time being cheap holds up.</p>

<h2 id="and-then-it-gets-murky-from-there">And then it gets murky from there</h2>

<p>Then there are the not so straightforward things. Are there particular reasons for the slowness of our tests? Are the factories that are being used to build up the data for these tests doing too much?  In our case, I’ve added <a href="https://github.com/test-prof/test-prof"><code>test-prof</code></a> to our app and run its factory profiler and detected no overly large factory there.</p>

<p>Is there a particular page which is slow, that a large majority of these tests hit? I noticed that when I ran a <em>headful</em> browser of Chrome (so I could see what each test was doing) that each of the tests hit the dashboard page, which has a collection of charts. Every test waited for these charts to finish loading before proceeding. I commented out the line of code which was rendering all of these charts, and saw a 20% improvement in test run time. Obviously we can’t comment these out all the time, but at least that’s something we could probably toggle on/off depending on if the test needed it. I’ll have to dig into this one.</p>

<h2 id="an-alternative-approach-for-feature-specs">An alternative approach for feature specs</h2>

<p>Could we have written these tests in a different way? Do they need to be full-on integration tests that set up data in the database, just to validate information appears in certain positions on the page?</p>

<p>I would say that for the less important pages, we don’t have to do such a setup. We have a frontend that’s built on React and TypeScript, with those TypeScript types being informed by our backend GraphQL API. And notably here we’re not just blindly grabbing things like <code>Purchase</code> off <code>@graphql/types</code>, we’re specifically defining types that match the relevant query, using code like:</p>

<pre><code class="language-tsx">type Merchant = NonNullable&lt;GetPurchaseDetailQuery['merchant']&gt;;
export type Purchase = NonNullable&lt;Merchant['purchase']&gt;;
</code></pre>

<p>The components expect the <em>exact</em> data from the query, and nothing different. We could write some frontend-focussed tests for these using React Testing Library, creating some tests that test:</p>

<ol>
  <li>When a particular component…</li>
  <li>receives a particular structure…</li>
  <li>it looks a certain way.</li>
</ol>

<p>There’s no need to interact with a database here, given that the automatically generated types are going to tell us if the data structure is right or wrong. We can write lighter-weight request specs that assert that, yes, when certain data exists in the database that our GraphQL API presents it in <em>this</em> particular format. The difficulty here is that the query structure used in these tests may vary over time from the structure defined in the components.</p>

<p>In my experience, these React Testing Library tests have been just as easy to write as the Capybara specs, and I’ve been able to setup the fixture data again thanks to the TypeScript types. These tests then run in <em>milliseconds</em> as opposed to <em>seconds</em>. The original RSpec tests for a particular part of our test suite, the Transaction Detail page, ran in 24.75 seconds. These same tests in React Testing Library take 1.66 seconds, and that’s including test runner setup time. That’s almost 15x faster.</p>

<p>I think there’s definitely some things we could work on pulling out of Capybara feature specs and into React Testing Library tests, to really bring down the slow tests. The biggest culprits for the slowness, looking purely at test duration have been the feature tests, by far.</p>

<h2 id="docker-setup-is-also-a-factor">Docker setup is also a factor</h2>

<p>The tests are run inside a Docker container which is built before most test runs rather than read from a cache, due to the ephemeral nature of the build machines. The base image for these containers has to come from <em>somewhere</em>, and that <em>somewhere</em> is a Docker registry. I’ve looked into ways of making the build machines use the cache with mixed success. It’s still an avenue I’d like to pursue, as it turns a 5-minute initial build step (that blocks every other step!) into one that runs for about half a minute. I’ve even seen some cases where that step can run in as quick as 14 seconds.</p>

<p>One aspect that has helped here is splitting the Dockerfile into a multi-stage build that builds it in 4 separate stages:</p>

<ol>
  <li>OS-level setup</li>
  <li>Ruby setup</li>
  <li>Node setup</li>
  <li>Final compilation for CSS + JS</li>
</ol>

<p>The Ruby + Node steps run concurrently, saving roughly 2-3 minutes compared to if they ran sequentially. We have investigated adding Docker-level caching for both the Ruby and Node steps, but haven’t gotten as far as having a system that reliably works for each build. It feels like a <code>cache-from</code> declared that matches the multi-stage target would work, but I can’t seem to make the build machines acknowledge that config and pull it in.</p>

<p>Or perhaps there’s a way to cache the packages gathered for those steps, storing them off the machines in some long-term storage and pulling them down before each build? Then Ruby + Node would only install the differences (if any) that are on that branch.</p>

<h2 id="slicing-up-the-app">Slicing up the app</h2>

<p>Finally, my absolute <em>golden path</em> idea on this topic is that the tests that run when you push a branch, should only be the tests related to the code that you changed. If I’m making changes on Part A of the system, then it doesn’t make sense to run tests for Part B on all branches. Running the entire test suite before a production deploy makes sense, but not on the earlier branches.</p>

<p>To that end, there’s probably investigative work to go on with this app where the app could be split into something like Hanami’s “slices”, so we have Slice A with its own tests, then if there’s file changes in Slice A then Slice A’s tests get run, but Slice B’s tests don’t. That seems like work that would be greater than many cooldown sprints in a row, and so I’m happy to leave that as just a thought bubble for the time-being.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[EDIT: I wrote these as notes for myself a few weeks ago when my brain wouldn’t stop spinning on this problem. Writing things down gets it out of my brain and lets me do simple things, like “engage in conversations” or “sleep”.]]></summary></entry><entry><title type="html">Scheduling with Ice Cube</title><link href="http://localhost:4000/2024/05/scheduling-with-ice-cube" rel="alternate" type="text/html" title="Scheduling with Ice Cube" /><published>2024-05-22T00:00:00+10:00</published><updated>2024-05-22T00:00:00+10:00</updated><id>http://localhost:4000/2024/05/scheduling-with-ice-cube</id><content type="html" xml:base="http://localhost:4000/2024/05/scheduling-with-ice-cube"><![CDATA[<p>I work in a system that needs to have recurring calendar-based payments happen, where the frequency of these payments is down to a (mostly) arbitrary selection by users. Recurring calendar events are interesting, especially if someone picks the <em>end of the month</em> for an event to occur. Some months that means the 30th, but it can also mean the 28th, 29th and 31st, depending on not only the <em>month</em> but also the <em>year</em>, thanks to leap years. Recurring payments can occur over multiple years, so one year there might be a payment done on the 29th of February one year, and another done on the 28th of February the year either side of that.</p>

<p>The frequency of these payments that we allow for in our system are weekly, fortnightly, every-4-weeks, monthly, quarterly, half-yearly, and yearly. When a schedule is created, we use the start date for the schedule as the basis for the ongoing payments. Schedules can optionally have an end date too, where those payments will stop happening.</p>

<p>On top of that, weekly and fortnightly payments can optionally have a day of the week chosen for payments, which means that they sometimes don’t line up with the declared start date.</p>

<p>Monthly payments can also have the same option, but instead of day of the week it’s day of the month. If someone selects the 31st as their billing day, we need to consider what we’d do in months like February, April, June, September and November, which don’t have those days.</p>

<p>All of this sounds like quite the headache, given it involves the two most difficult things: <em>time</em> and <em>money</em>. Putting the money thing to one side for the moment, we’ll stay focussed on just the <em>time</em> thing.</p>

<p>To help with the scheduling calculation, we use the <a href="https://rubygems.org/gems/ice_cube">ice_cube</a> gem.</p>

<p>Let’s say that we have a schedule that:</p>

<ul>
  <li>Starts today: <code>2024-05-22</code>.</li>
  <li>Has no end date</li>
  <li>Reoccurs monthly</li>
  <li>Day of the month: 31st</li>
</ul>

<p>With <code>ice_cube</code>, we can write code to generate schedules:</p>

<pre><code class="language-ruby">start_date = Date.parse('2024-05-22')

schedule_rule = IceCube::Rule.monthly.day_of_month(31)

schedule = IceCube::Schedule.new(start_date) do |s|
  s.add_recurrence_rule(schedule_rule)
end

puts schedule.first(10)
</code></pre>

<p>This seems innocent enough. But if we run it, we’ll see that it’s not quite right:</p>

<pre><code class="language-text">2024-05-31 00:00:00 +1000
2024-07-31 00:00:00 +1000
2024-08-31 00:00:00 +1000
2024-10-31 00:00:00 +1100
2024-12-31 00:00:00 +1100
2025-01-31 00:00:00 +1100
2025-03-31 00:00:00 +1100
2025-05-31 00:00:00 +1000
2025-07-31 00:00:00 +1000
2025-08-31 00:00:00 +1000
</code></pre>

<p>We asked for a monthly recurring schedule, but we also said that this has to be on the 31st day of the month. The <code>ice_cube</code> gem dutifully follows our instructions, and sets a reoccurring schedule for all months with 31 days and the first 5 months there are May, July, August, October, and December.</p>

<p>We would also see this bug if we specified the 30th or 29th for the day of the month.</p>

<p>To fix this, we can instead specify a negative day:</p>

<pre><code class="language-ruby">start_date = Date.parse('2024-05-22')

schedule_rule = IceCube::Rule.monthly.day_of_month(-1)

schedule = IceCube::Schedule.new(start_date) do |s|
  s.add_recurrence_rule(schedule_rule)
end

puts schedule.next_occurrences(10)
</code></pre>

<p>This will produce the following schedule:</p>

<pre><code class="language-text">2024-05-31 00:00:00 +1000
2024-06-30 00:00:00 +1000
2024-07-31 00:00:00 +1000
2024-08-31 00:00:00 +1000
2024-09-30 00:00:00 +1000
2024-10-31 00:00:00 +1100
2024-11-30 00:00:00 +1100
2024-12-31 00:00:00 +1100
2025-01-31 00:00:00 +1100
2025-02-28 00:00:00 +1100
</code></pre>

<p>We can do similar scheduling rules for the things I mentioned earlier too, such as scheduling things on Mondays:</p>

<pre><code class="language-ruby">schedule_rule = IceCube::Rule.weekly.day(:monday)
</code></pre>

<pre><code class="language-text">2024-05-27 00:00:00 +1000
2024-06-03 00:00:00 +1000
2024-06-10 00:00:00 +1000
2024-06-17 00:00:00 +1000
2024-06-24 00:00:00 +1000
2024-07-01 00:00:00 +1000
2024-07-08 00:00:00 +1000
2024-07-15 00:00:00 +1000
2024-07-22 00:00:00 +1000
2024-07-29 00:00:00 +1000
</code></pre>

<p>The <a href="https://github.com/ice-cube-ruby/ice_cube">README for the gem</a> contains plenty of other examples.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I work in a system that needs to have recurring calendar-based payments happen, where the frequency of these payments is down to a (mostly) arbitrary selection by users. Recurring calendar events are interesting, especially if someone picks the end of the month for an event to occur. Some months that means the 30th, but it can also mean the 28th, 29th and 31st, depending on not only the month but also the year, thanks to leap years. Recurring payments can occur over multiple years, so one year there might be a payment done on the 29th of February one year, and another done on the 28th of February the year either side of that.]]></summary></entry><entry><title type="html">Thought Experiment: Without React or GraphQL</title><link href="http://localhost:4000/2024/05/without-react-or-graphql" rel="alternate" type="text/html" title="Thought Experiment: Without React or GraphQL" /><published>2024-05-20T00:00:00+10:00</published><updated>2024-05-20T00:00:00+10:00</updated><id>http://localhost:4000/2024/05/without-react-or-graphql</id><content type="html" xml:base="http://localhost:4000/2024/05/without-react-or-graphql"><![CDATA[<p>I’ve spent a great deal of my writing time in the past few years arguing for GraphQL in my <a href="https://pragprog.com/titles/d-rbgql/graphql-for-rails-developers/">GraphQL for Rails Developers</a> and its frontend companion Apollo in the <a href="https://pragprog.com/titles/d-rbgql/graphql-for-rails-developers/">Apollo Handbook</a>. I think these are very good tools for providing a clear separation between an API layer and a frontend layer.</p>

<p>But in saying that, I acknowledge there is no silver bullet for software development. So what would I do if I <em>couldn’t</em> use React or GraphQL?</p>

<p>To replace React on the frontend, I would use <a href="https://viewcomponent.org/">View Component</a> as I have written about <a href="https://ryanbigg.com/2024/01/view-components-table-edition">here</a> and <a href="https://ryanbigg.com/2023/06/rails-7-react-typescript-setup">here</a>. I could also be convinced to use <a href="https://www.phlex.fun/">Phlex</a>.</p>

<p>I think having a typed layer between your database and view is just something that <em>makes sense</em>, and so to that end I would define a <em>separate</em> class for the data types for these components, using <code>dry-types</code> and then pass objects of those classes to the view, in a way that if you squint hard enough you could see it as the Presenter Pattern. I proposed something similar to this <a href="https://ryanbigg.com/2022/03/typed-view-components">two years ago in my “Typed View Components” post</a></p>

<p>Riffing on the example from that post, I would have this as:</p>

<pre><code class="language-ruby">class RefundComponent &lt; ViewComponent::Base
  extend Dry::Initializer
  Types = Dry.Types()

  class Refund &lt; Dry::Struct
    schema schema.strict

    attribute :standalone, Types::Bool
    attribute :amount, Types::Float
    attribute :currency, Types::String
  end

  option :refund, Refund
end
</code></pre>

<p>This allows you to keep together the logic of the component (both its Ruby code and its associated views) and the presenter in one directory.</p>

<p>In the controller, the code would look like this:</p>

<pre><code class="language-ruby">refund = RefundComponent::Refund.new(
  standalone: @refund.standalone?
  amount: @refund.amount,
  currency: @refund.currency,
)

@refund_component = RefundComponent.new(refund: refund)
</code></pre>

<p>This would still give us an interface <em>similar</em> to GraphQL, where the connecting layer between the database and the frontend is still typed. I think it’s teetering on the edge of being too verbose, but in all things trade-offs.</p>

<p>You then don’t end up exposing any way of doing database queries to the view, which would help prevent N+1 queries. And you can test your views in isolation from the database too. The <code>refund</code> passed to the component doesn’t have to come from the database; it could be a stubbed object, as long as it responds to the right methods.</p>

<p>In the view file itself you might or might not get smart tab-completion like you do within TypeScript-powered GraphQL code, but I think that’s a fair trade-off.</p>

<p>This whole approach trades off React’s “reactivity” as well, so there’s no state management going on here or DOM updating when the state changes. There are probably ways around this (like Hotwire, etc.) but I haven’t gone down those paths yet.</p>

<p>Another benefit here is that all the code is in one language, rather than three (Ruby, GraphQL and TypeScript), and that might make it easier for frontend-adverse people to pick it up as well.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I’ve spent a great deal of my writing time in the past few years arguing for GraphQL in my GraphQL for Rails Developers and its frontend companion Apollo in the Apollo Handbook. I think these are very good tools for providing a clear separation between an API layer and a frontend layer.]]></summary></entry><entry><title type="html">What was that branch?</title><link href="http://localhost:4000/2024/05/what-was-that-branch" rel="alternate" type="text/html" title="What was that branch?" /><published>2024-05-14T00:00:00+10:00</published><updated>2024-05-14T00:00:00+10:00</updated><id>http://localhost:4000/2024/05/what-was-that-branch</id><content type="html" xml:base="http://localhost:4000/2024/05/what-was-that-branch"><![CDATA[<p>When I’m working in an app I tend to have multiple branches on the go at any one time while waiting for feedback on those branches, be that feedback from CI systems or people. Occasionally, it’s a few days / weeks between visits to a branch because the flow of work meant it that way. And sometimes, I forget what the branch name was.</p>

<p>To help with this, I’ve got this function in my <code>~/.zshrc</code>:</p>

<pre><code>fbr () {
	local branches branch
	branches=$(git for-each-ref --count=30 --sort=-committerdate refs/heads/ --format="%(refname:short)")  &amp;&amp; branch=$(echo "$branches" |
  fzf-tmux -d $(( 2 + $(wc -l &lt;&lt;&lt; "$branches") )) +m)  &amp;&amp; git checkout $(echo "$branch" | sed "s/.* //" | sed "s#remotes/[^/]*/##")
}
</code></pre>

<p>This complicated looking function finds the 30 most recent local branches and presents them in a date-ordered list using <code>fzf-tmux</code>. To pick a branch, I can type part of the branch name if I remember it, and <code>fzf</code> will filter the list of branches to just the ones that match that. When I find the branch I want, I hit enter and this will swap over to the branch.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[When I’m working in an app I tend to have multiple branches on the go at any one time while waiting for feedback on those branches, be that feedback from CI systems or people. Occasionally, it’s a few days / weeks between visits to a branch because the flow of work meant it that way. And sometimes, I forget what the branch name was.]]></summary></entry></feed>